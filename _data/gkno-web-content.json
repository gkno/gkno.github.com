{
  "__gkno__": {
    "commit": "15fc46918603f46dbeed639293ea0e6339370704", 
    "date": "October 2015", 
    "version": "2.37.2"
  }, 
  "categories": {
    "Alignment": [
      "bwa-se", 
      "bwa", 
      "mosaik"
    ], 
    "BAM-processing": [
      "add-read-group", 
      "bam-to-fastq", 
      "bedtools-coverage", 
      "filter-bam", 
      "gatk-gvcf", 
      "get-region-coverage", 
      "index-bam", 
      "merge-bam", 
      "tangram-bam"
    ], 
    "FASTA-processing": [
      "build-mosaik-reference", 
      "bwa-index", 
      "fasta-dictionary", 
      "index-fasta", 
      "tangram-index"
    ], 
    "SV-discovery": [
      "tangram-index", 
      "tangram"
    ], 
    "Scripts": [
      "find-cds", 
      "regions-coord", 
      "regions-dict"
    ], 
    "Tools": [
      "bedtools-coverage"
    ], 
    "VCF-processing": [
      "get-indels", 
      "index-vcf", 
      "merge-vcf", 
      "standardize-vcf", 
      "subset-vcf", 
      "vcf-primitives"
    ], 
    "Variant-discovery": [
      "compress-vcf", 
      "freebayes", 
      "gatk-genotype", 
      "gatk-gvcf", 
      "gatk-vqsr", 
      "normalize-vcf", 
      "tangram-index", 
      "tangram"
    ], 
    "Visualisation": [
      "coverage"
    ], 
    "kmer-processing": [
      "kmer-histogram"
    ]
  }, 
  "pipelines": {
    "add-read-group": {
      "arguments": [
        {
          "data type": "flag", 
          "description": "Removes all read groups from the header.", 
          "long form argument": "--clear", 
          "short form argument": "-c"
        }, 
        {
          "data type": "string", 
          "description": "only read data from this genomic region.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "Removes this sample name and all associated read groups from the header.", 
          "long form argument": "--remove", 
          "short form argument": "-v"
        }, 
        {
          "data type": "string", 
          "description": "Apply this sample name to the BAM file.", 
          "long form argument": "--sample", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "The input BAM file(s).", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "Apply this read group to the BAM file.", 
          "long form argument": "--read-group", 
          "short form argument": "-g"
        }
      ], 
      "description": "Add or remove sample and read group information to a BAM file."
    }, 
    "bam-to-fastq": {
      "arguments": [
        {
          "data type": "string", 
          "description": "Base output name for generated output files.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "Read name extension to use for first read in a pair default is '/1'.", 
          "long form argument": "--first-mate-extension", 
          "short form argument": "-f"
        }, 
        {
          "data type": "flag", 
          "description": "Add the read name/extension to the '+' line of the fastq records.", 
          "long form argument": "--add-name-to-plus", 
          "short form argument": "-a"
        }, 
        {
          "data type": "string", 
          "description": "The input SAM / BAM file to convert.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "Reference file for converting '=' in the sequence to the actual base if '=' are found and the refFile is not specified, 'N' is written to the FASTQ.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "flag", 
          "description": "Print the parameter settings to stderr.", 
          "long form argument": "--params", 
          "short form argument": "-p"
        }, 
        {
          "data type": "flag", 
          "description": "Process the BAM as readName sorted instead of coordinate if the header does not indicate a sort order.", 
          "long form argument": "--read-name", 
          "short form argument": "-n"
        }, 
        {
          "data type": "flag", 
          "description": "Do not reverse complement reads marked as reverse", 
          "long form argument": "--no-reverse", 
          "short form argument": "-v"
        }, 
        {
          "data type": "flag", 
          "description": "Generate 1 interleaved (merged) FASTQ for paired-ends (unpaired in a separate file) use firstOut to override the filename of the interleaved file.", 
          "long form argument": "--merge", 
          "short form argument": "-m"
        }, 
        {
          "data type": "flag", 
          "description": "Do not expect an EOF block on a bam file.", 
          "long form argument": "--no-eof", 
          "short form argument": "-e"
        }, 
        {
          "data type": "string", 
          "description": "Read name extension to use for second read in a pair default is '/2'.", 
          "long form argument": "--second-mate-extension", 
          "short form argument": "-s"
        }
      ], 
      "description": "Convert a BAM file back into a FASTQ file."
    }, 
    "bedtools-coverage": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The input genome file. This is a tab delimited file, with structure: <chromName><TAB><chromSize>.", 
          "long form argument": "--genome-file", 
          "short form argument": "-g"
        }, 
        {
          "data type": "flag", 
          "description": "Report depth in BedGraph format. For details, see: genome.ucsc.edu/goldenPath/help/bedgraph.html.", 
          "long form argument": "--bed-graph", 
          "short form argument": "-bg"
        }, 
        {
          "data type": "string", 
          "description": "The output coverage file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "flag", 
          "description": "Treat \"split\" BAM or BED12 entries as distinct BED intervals. when computing coverage. For BAM files, this uses the CIGAR \"N\" and \"D\" operations  to infer the blocks for computing coverage. For BED12 files, this uses the BlockCount, BlockStarts, and BlockEnds fields (i.e., columns 10,11,12).", 
          "long form argument": "--split", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "Calculate coverage of intervals from a specific strand. With BED files, requires at least 6 columns (strand is column 6). Can take the values + or -.", 
          "long form argument": "--strand", 
          "short form argument": "-t"
        }, 
        {
          "data type": "flag", 
          "description": "Calculate coverage of 5\" positions (instead of entire interval).", 
          "long form argument": "--five-prime", 
          "short form argument": "-5"
        }, 
        {
          "data type": "flag", 
          "description": "Calculate coverage of 3\" positions (instead of entire interval).", 
          "long form argument": "--three-prime", 
          "short form argument": "-3"
        }, 
        {
          "data type": "string", 
          "description": "The input sorted BAM file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "flag", 
          "description": "Adds a UCSC/Genome-Browser track line definition in the first line of the output. See here for more details about track line definition: http://genome.ucsc.edu/goldenPath/help/bedgraph.html. NOTE: When adding a trackline definition, the output BedGraph can be easily uploaded to the Genome Browser as a custom track, BUT CAN NOT be converted into a BigWig file (w/o removing the first line).", 
          "long form argument": "--track-line", 
          "short form argument": "-l"
        }, 
        {
          "data type": "flag", 
          "description": "Scale the coverage by a constant factor. Each coverage value is multiplied by this factor before being reported. Useful for normalizing coverage by, e.g., reads per million (RPM). Default is 1.0; i.e., unscaled.", 
          "long form argument": "--scale", 
          "short form argument": "-c"
        }, 
        {
          "data type": "flag", 
          "description": "Report depth in BedGraph format, as with --bed-graph. However with this option, regions with zero coverage are also reported. This allows one to quickly extract all regions of a genome with 0 coverage by applying: \"grep -w 0$\" to the output.", 
          "long form argument": "--bed-graph-with-zero", 
          "short form argument": "-bg0"
        }, 
        {
          "data type": "flag", 
          "description": "Report the depth at each genome position (with zero-based coordinates). Reports only non-zero positions. Default behavior is to report a histogram.", 
          "long form argument": "--depth-zero-based", 
          "short form argument": "-d0"
        }, 
        {
          "data type": "flag", 
          "description": "Report the depth at each genome position (with one-based coordinates). Default behavior is to report a histogram.", 
          "long form argument": "--depth-one-based", 
          "short form argument": "-d1"
        }, 
        {
          "data type": "integer", 
          "description": "Combine all positions with a depth >= max into a single bin in the histogram. Irrelevant for --depth-one-based and --bed-graph.", 
          "long form argument": "--combine-max-depth", 
          "short form argument": "-m"
        }, 
        {
          "data type": "flag", 
          "description": "Writes additional track line definition parameters in the first line. Example: --track-options 'name=\"My Track\" visibility=2 color=255,30,30'. Note the use of single-quotes if you have spaces in your parameters.", 
          "long form argument": "--track-options", 
          "short form argument": "-to"
        }
      ], 
      "description": "Population call variants using Freebayes, filtering the results with standard filtering methods."
    }, 
    "build-mosaik-reference": {
      "arguments": [
        {
          "data type": "string", 
          "description": "Reference fasta file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The output fasta reference including the moblist.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The mobile element reference fasta file.", 
          "long form argument": "--mobile-element-fasta", 
          "short form argument": "-m"
        }, 
        {
          "data type": "integer", 
          "description": "Record all hashes in the genome of this size. [4 - 32]", 
          "long form argument": "--hash-size", 
          "short form argument": "-hs"
        }
      ], 
      "description": "Concatenate reference fasta files and generate a Mosaik reference and jump database."
    }, 
    "bwa": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output BAM file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The input fastq file (second mate).", 
          "long form argument": "--fastq2", 
          "short form argument": "-q2"
        }, 
        {
          "data type": "integer", 
          "description": "The number of threads for BWA-mem.", 
          "long form argument": "--threads-bwa", 
          "short form argument": "-tb"
        }, 
        {
          "data type": "string", 
          "description": "The input fastq file (first mate).", 
          "long form argument": "--fastq", 
          "short form argument": "-q"
        }, 
        {
          "data type": "string", 
          "description": "The reference FASTA file prefix.", 
          "long form argument": "--reference-prefix", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The sample id.", 
          "long form argument": "--sample-id", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "The platform id (e.g. ILLUMINA).", 
          "long form argument": "--platform-id", 
          "short form argument": "-p"
        }, 
        {
          "data type": "string", 
          "description": "The read group id.", 
          "long form argument": "--read-group-id", 
          "short form argument": "-id"
        }
      ], 
      "description": "Align paired-end fastq files using BWA mem, converting the result to BAM."
    }, 
    "bwa-index": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The reference FASTA file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The output FM index filename stub.", 
          "long form argument": "--index", 
          "short form argument": "-x"
        }, 
        {
          "data type": "string", 
          "description": "BWT construction algorithm: bwtsw or is [auto].", 
          "long form argument": "--bwt-algorithm", 
          "short form argument": "-a"
        }
      ], 
      "description": "Generate the FM-index for use with bwa alignment."
    }, 
    "bwa-se": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output BAM file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "integer", 
          "description": "The number of threads for BWA-mem.", 
          "long form argument": "--threads-bwa", 
          "short form argument": "-tb"
        }, 
        {
          "data type": "string", 
          "description": "The input fastq file (first mate).", 
          "long form argument": "--fastq", 
          "short form argument": "-q"
        }, 
        {
          "data type": "string", 
          "description": "The reference FASTA file prefix.", 
          "long form argument": "--reference-prefix", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The sample id.", 
          "long form argument": "--sample-id", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "The platform id (e.g. ILLUMINA).", 
          "long form argument": "--platform-id", 
          "short form argument": "-p"
        }, 
        {
          "data type": "string", 
          "description": "The read group id.", 
          "long form argument": "--read-group-id", 
          "short form argument": "-id"
        }
      ], 
      "description": "Align single-end fastq files using BWA mem, converting the result to BAM."
    }, 
    "compress-vcf": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The file to be compressed.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }
      ], 
      "description": "Compress a VCF file using bgzip and index with tabix."
    }, 
    "coverage": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output pdf absolute coverage plot file with zero coverage bases removed.", 
          "long form argument": "--out-scaled", 
          "short form argument": "-os"
        }, 
        {
          "data type": "flag", 
          "description": "Plot the bin of reads with zero coverage.", 
          "long form argument": "--include-zero", 
          "short form argument": "-z"
        }, 
        {
          "data type": "string", 
          "description": "The output pdf absolute coverage plot file.", 
          "long form argument": "--out-absolute", 
          "short form argument": "-oc"
        }, 
        {
          "data type": "string", 
          "description": "The input sorted BAM file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "integer", 
          "description": "The maximum value for the x axis for the absolute coverage plot [determined by data, or --combine-max-depth].", 
          "long form argument": "--x-axis-maximum", 
          "short form argument": "-x"
        }, 
        {
          "data type": "string", 
          "description": "The output pdf scaled proportional coverage plot file.", 
          "long form argument": "--out-proportional-scaled", 
          "short form argument": "-ops"
        }, 
        {
          "data type": "flag", 
          "description": "Plot the raw read counts, rather than the percentage of the reads with each coverage.", 
          "long form argument": "--read-counts", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The output pdf proportional coverage plot file.", 
          "long form argument": "--out-proportional", 
          "short form argument": "-or"
        }, 
        {
          "data type": "flag", 
          "description": "Use a log scale for the y-axis.", 
          "long form argument": "--log-scale", 
          "short form argument": "-l"
        }, 
        {
          "data type": "integer", 
          "description": "Combine all positions with a depth >= max into a single bin in the histogram.", 
          "long form argument": "--combine-max-depth", 
          "short form argument": "-c"
        }, 
        {
          "data type": "string", 
          "description": "A sorted list of reference sequences to use when plotting the histogram.", 
          "long form argument": "--reference-sequences", 
          "short form argument": "-s"
        }
      ], 
      "description": "Calculate the genome coverage across reference sequences (usually chromosomes), generating R-plots."
    }, 
    "fasta-dictionary": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The input reference FASTA file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "the output sequence dictionary.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }
      ], 
      "description": "Generate a dictionary containing all of the sequences in the input reference fasta."
    }, 
    "filter-bam": {
      "arguments": [
        {
          "data type": "bool", 
          "description": "Keep only alignments with mate on reverese strand?", 
          "long form argument": "--is-mate-reverse-strand", 
          "short form argument": "-imr"
        }, 
        {
          "data type": "string", 
          "description": "only read data from this genomic region.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments with mates that mapped.", 
          "long form argument": "--is-mate-mapped", 
          "short form argument": "-imm"
        }, 
        {
          "data type": "string", 
          "description": "Keep reads with length that matches pattern.", 
          "long form argument": "--length", 
          "short form argument": "-g"
        }, 
        {
          "data type": "string", 
          "description": "Keep reads with this key=>value pair.", 
          "long form argument": "--tag", 
          "short form argument": "-t"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments marked as second mate?", 
          "long form argument": "--is-second-mate", 
          "short form argument": "-ism"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only singletons?", 
          "long form argument": "--is-singleton", 
          "short form argument": "-isi"
        }, 
        {
          "data type": "string", 
          "description": "The output filtered and merged BAM file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The input BAM file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments that are marked as duplicate?", 
          "long form argument": "--is-duplicate", 
          "short form argument": "-id"
        }, 
        {
          "data type": "string", 
          "description": "Keep reads with name that matches pattern.", 
          "long form argument": "--name", 
          "short form argument": "-n"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments that were sequenced as paired?", 
          "long form argument": "--is-paired", 
          "short form argument": "-ipr"
        }, 
        {
          "data type": "string", 
          "description": "Keep reads with mapping qualities that match pattern.", 
          "long form argument": "--mapping-quality", 
          "short form argument": "-mq"
        }, 
        {
          "data type": "integer", 
          "description": "Keep reads with this *exact* alignment flag (for more detailed queries, see 'Alignment flag filters').", 
          "long form argument": "--alignment-flag", 
          "short form argument": "-a"
        }, 
        {
          "data type": "string", 
          "description": "Keep reads with motif that matches pattern.", 
          "long form argument": "--query-bases", 
          "short form argument": "-q"
        }, 
        {
          "data type": "string", 
          "description": "Keep reads with insert size that matches pattern.", 
          "long form argument": "--insert-size", 
          "short form argument": "-z"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments that were mapped?", 
          "long form argument": "--is-mapped", 
          "short form argument": "-im"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments that failed QC?", 
          "long form argument": "--is-failed-qc", 
          "short form argument": "-if"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments on reverse strand?", 
          "long form argument": "--is-reverse-strand", 
          "short form argument": "-ir"
        }, 
        {
          "data type": "string", 
          "description": "the filter script file (see bamtools documentation for more information).", 
          "long form argument": "--script", 
          "short form argument": "-s"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments marked as first mate?", 
          "long form argument": "--is-first-mate", 
          "short form argument": "-ifm"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments marked as primary?", 
          "long form argument": "--is-primary-alignment", 
          "short form argument": "-ipa"
        }, 
        {
          "data type": "bool", 
          "description": "Keep only alignments that passed PE resolution?", 
          "long form argument": "--is-proper-pair", 
          "short form argument": "-ipp"
        }
      ], 
      "description": "Filter a set of BAM files."
    }, 
    "find-cds": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The list of genomic region corresponding to the CDS (ordered to correspond with the transcripts file).", 
          "long form argument": "--transcript-list", 
          "short form argument": "-tl"
        }, 
        {
          "data type": "string", 
          "description": "The input gff file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The list of genomic region corresponding to the CDS (ordered to correspond with the transcripts file).", 
          "long form argument": "--region-list", 
          "short form argument": "-rl"
        }, 
        {
          "data type": "string", 
          "description": "The input list of reference sequences to consider.", 
          "long form argument": "--sequences", 
          "short form argument": "-s"
        }
      ], 
      "description": "Search through a GFF (GTF) file and extract all CDS entries. Two output files are generated: a file containing a list of all genomic regions and a file with the corresponding gene name, transcript id and exon number."
    }, 
    "freebayes": {
      "arguments": [
        {
          "data type": "flag", 
          "description": "Use stringent input base and mapping quality filters. Equivalent to -m 30 -q 20 -R 0 -S 0", 
          "long form argument": "--standard-filters", 
          "short form argument": "-sf"
        }, 
        {
          "data type": "integer", 
          "description": "To detect interrupted repeats, build across sequence until it has entropy > N bits per bp.  (default: 0, off)", 
          "long form argument": "--min-repeat-entropy", 
          "short form argument": "-mre"
        }, 
        {
          "data type": "integer", 
          "description": "Count mismatches toward --read-mismatch-limit if the base quality of the mismatch is >= Q. default: 10", 
          "long form argument": "--mismatch-base-quality-threshold", 
          "short form argument": "-Q"
        }, 
        {
          "data type": "string", 
          "description": "Use FILE as the reference sequence for analysis.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "float", 
          "description": "The expected mutation rate or pairwise nucleotide diversity among the population under analysis.  This serves as the single parameter to the Ewens Sampling Formula prior model. default: 0.001.", 
          "long form argument": "--theta", 
          "short form argument": "-T"
        }, 
        {
          "data type": "string", 
          "description": "<chrom>:<start_position>..<end_position>. Limit analysis to the specified region, 0-base coordinates, end_position not included (same as BED format).", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "flag", 
          "description": "Ignore complex events (composites of other classes).", 
          "long form argument": "--no-complex", 
          "short form argument": "-u"
        }, 
        {
          "data type": "flag", 
          "description": "Ignore multi-nuceotide polymorphisms, MNPs.", 
          "long form argument": "--no-mnps", 
          "short form argument": "-X"
        }, 
        {
          "data type": "integer", 
          "description": "Exclude alignments from analysis if they have a mapping quality less than Q.  default: 0", 
          "long form argument": "--min-mapping-quality", 
          "short form argument": "-mmq"
        }, 
        {
          "data type": "flag", 
          "description": "Report genotypes using the maximum-likelihood estimate provided from genotype likelihoods.", 
          "long form argument": "--report-genotype-likelihood-max", 
          "short form argument": "-rgl"
        }, 
        {
          "data type": "string", 
          "description": "A file containing per-sample estimates of contamination, such as those generated by VerifyBamID.  The format should be: sample p(read=R|genotype=AR) p(read=A|genotype=AA). Sample '*' can be used to set default contamination estimates.", 
          "long form argument": "--contamination-estimates", 
          "short form argument": "-ce"
        }, 
        {
          "data type": "integer", 
          "description": "Limit posterior integration to samples where the second-best genotype likelihood is no more than log(N) from the highest genotype likelihood for the sample.  default: ~unbounded.", 
          "long form argument": "--genotype-variant-threshold", 
          "short form argument": "-S"
        }, 
        {
          "data type": "string", 
          "description": "Assign mapping quality of MQ to the reference allele at each site and base quality of BQ. default: 100,60", 
          "long form argument": "--reference-quality", 
          "short form argument": "-rq"
        }, 
        {
          "data type": "flag", 
          "description": "Calculate the marginal probability of genotypes and report as GQ in each sample field in the VCF output.", 
          "long form argument": "--genotype-qualities", 
          "short form argument": "-gq"
        }, 
        {
          "data type": "flag", 
          "description": "Output all alleles which pass input filters, regardless of genotyping outcome or model.", 
          "long form argument": "--pooled-continuous", 
          "short form argument": "-pc"
        }, 
        {
          "data type": "float", 
          "description": "Exclude reads with more than N [0,1] fraction of mismatches where each mismatch has base quality >= mismatch-base-quality-threshold. default: 1.0", 
          "long form argument": "--read-max-mismatch-fraction", 
          "short form argument": "-z"
        }, 
        {
          "data type": "integer", 
          "description": "Evaluate only the best N SNP alleles, ranked by sum of supporting quality scores.  (Set to 0 to use all; default: all)", 
          "long form argument": "--use-best-n-alleles", 
          "short form argument": "-n"
        }, 
        {
          "data type": "flag", 
          "description": "Equivalent to --pooled-discrete --hwe-priors-off and removal of Ewens Sampling Formula component of priors.", 
          "long form argument": "--no-population-priors", 
          "short form argument": "-k"
        }, 
        {
          "data type": "string", 
          "description": "bam index file.", 
          "long form argument": "--index", 
          "short form argument": "-x"
        }, 
        {
          "data type": "string", 
          "description": "The output filtered VCF file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "Specifies a filter to apply to the info fields of records, removes alleles which do not pass the filter.", 
          "long form argument": "--filter-expression", 
          "short form argument": "-f"
        }, 
        {
          "data type": "float", 
          "description": "Report sites if the probability that there is a polymorphism at the site is greater than N.  default: 0.0001.", 
          "long form argument": "--pvar", 
          "short form argument": "-pv"
        }, 
        {
          "data type": "float", 
          "description": "Require at least this fraction of observations supporting an alternate allele within a single individual in the in order to evaluate the position.  default: 0.2", 
          "long form argument": "--min-alternate-fraction", 
          "short form argument": "-maf"
        }, 
        {
          "data type": "integer", 
          "description": "Exclude alleles from analysis if their supporting base quality is less than Q.  default: 0", 
          "long form argument": "--min-base-quality", 
          "short form argument": "-mbq"
        }, 
        {
          "data type": "string", 
          "description": "Add FILE to the set of BAM files to be analyzed.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "integer", 
          "description": "Integrate no deeper than the Nth best genotype by likelihood when genotyping. default: 6.", 
          "long form argument": "--genotyping-max-banddepth", 
          "short form argument": "-gmb"
        }, 
        {
          "data type": "integer", 
          "description": "Allow haplotype calls with contiguous embedded matches of up to this length. default: 3", 
          "long form argument": "--haplotype-length", 
          "short form argument": "-hl"
        }, 
        {
          "data type": "flag", 
          "description": "Ignore insertion and deletion alleles.", 
          "long form argument": "--no-indels", 
          "short form argument": "-ni"
        }, 
        {
          "data type": "string", 
          "description": "When specified, only variant alleles provided in this input VCF will be used for the construction of complex or haplotype alleles.", 
          "long form argument": "--haplotype-basis-alleles", 
          "short form argument": "-hba"
        }, 
        {
          "data type": "string", 
          "description": "The description of the filter to include in the VCF header.", 
          "long form argument": "--filter-tag-description", 
          "short form argument": "-fd"
        }, 
        {
          "data type": "flag", 
          "description": "Disable incorporation of prior expectations about observations. Uses read placement probability, strand balance probability, and read position (5'-3') probability.", 
          "long form argument": "--binomial-obs-priors-off", 
          "short form argument": "-V"
        }, 
        {
          "data type": "string", 
          "description": "Read length-dependent allele observation biases from FILE. The format is [length] [alignment efficiency relative to reference] where the efficiency is 1 if there is no relative observation bias.", 
          "long form argument": "--observation-bias", 
          "short form argument": "-ob"
        }, 
        {
          "data type": "string", 
          "description": "Read a copy number map from the BED file FILE, which has the format: reference sequence, start, end, sample name, copy number ... for each region in each sample which does not have the default copy number as set by --ploidy.", 
          "long form argument": "--cnv-map", 
          "short form argument": "-cnv"
        }, 
        {
          "data type": "integer", 
          "description": "Sets the default ploidy for the analysis to N.  default: 2.", 
          "long form argument": "--ploidy", 
          "short form argument": "-p"
        }, 
        {
          "data type": "flag", 
          "description": "This flag includes the reference allele in the analysis as if it is another sample from the same population.", 
          "long form argument": "--use-reference-allele", 
          "short form argument": "-Z"
        }, 
        {
          "data type": "float", 
          "description": "An estimate of contamination to use for all samples.  default: 10e-9", 
          "long form argument": "--prob-contamination", 
          "short form argument": "-pco"
        }, 
        {
          "data type": "string", 
          "description": "Use variants reported in VCF file as input to the algorithm. Variants in this file will be treated as putative variants even if there is not enough support in the data to pass input filters.", 
          "long form argument": "--variant-input", 
          "short form argument": "-v"
        }, 
        {
          "data type": "integer", 
          "description": "Exclude reads with more than N separate gaps. default: ~unbounded", 
          "long form argument": "--read-indel-limit", 
          "short form argument": "-e"
        }, 
        {
          "data type": "flag", 
          "description": "Use mapping quality of alleles when calculating data likelihoods.", 
          "long form argument": "--use-mapping-quality", 
          "short form argument": "-j"
        }, 
        {
          "data type": "integer", 
          "description": "Exclude reads with more than N mismatches where each mismatch has base quality >= mismatch-base-quality-threshold. default: ~unbounded", 
          "long form argument": "--read-mismatch-limit", 
          "short form argument": "-U"
        }, 
        {
          "data type": "integer", 
          "description": "Exclude reads with more than N base mismatches, ignoring gaps with quality >= mismatch-base-quality-threshold. default: ~unbounded", 
          "long form argument": "--read-snp-limit", 
          "short form argument": "-rsl"
        }, 
        {
          "data type": "integer", 
          "description": "Limit estimated observation quality by capping base quality at Q.", 
          "long form argument": "--base-quality-cap", 
          "short form argument": "-bqc"
        }, 
        {
          "data type": "integer", 
          "description": "Consider any allele in which and the sum of mapping qualities of supporting reads is at least Q. default: 0", 
          "long form argument": "--min-supporting-mapping-qsum", 
          "short form argument": "-Y"
        }, 
        {
          "data type": "flag", 
          "description": "Include duplicate-marked alignments in the analysis. Default: exclude duplicates marked as such in alignments.", 
          "long form argument": "--use-duplicate-reads", 
          "short form argument": "-ud"
        }, 
        {
          "data type": "flag", 
          "description": "Disable estimation of the probability of the combination arising under HWE given the allele frequency as estimated by observation frequency.", 
          "long form argument": "--hwe-priors-off", 
          "short form argument": "-w"
        }, 
        {
          "data type": "integer", 
          "description": "When assembling observations across repeats, require the total repeat length at least this many bp. default: 5", 
          "long form argument": "--min-repeat-size", 
          "short form argument": "-mrs"
        }, 
        {
          "data type": "integer", 
          "description": "Consider any allele in which the sum of qualities of supporting observations is at least Q. default: 0", 
          "long form argument": "--min-supporting-allele-qsum", 
          "short form argument": "-msa"
        }, 
        {
          "data type": "integer", 
          "description": "Use a weighted sum of base qualities around an indel, scaled by the distance from the indel.  By default use a minimum BQ in flanking sequence.", 
          "long form argument": "--harmonic-indel-quality", 
          "short form argument": "-H"
        }, 
        {
          "data type": "string", 
          "description": "The text to add to the filter field for each record in the VCF file that satisfies the filter expression.", 
          "long form argument": "--filter-tag", 
          "short form argument": "-ft"
        }, 
        {
          "data type": "float", 
          "description": "Incorporate non-independence of reads by scaling successive observations by this factor during data likelihood calculations.  default: 0.9", 
          "long form argument": "--read-dependence-factor", 
          "short form argument": "-D"
        }, 
        {
          "data type": "integer", 
          "description": "Allow complex alleles with contiguous embedded matches of up to this length.", 
          "long form argument": "--max-complex-gap", 
          "short form argument": "-E"
        }, 
        {
          "data type": "integer", 
          "description": "Require at least this count of observations supporting an alternate allele within a single individual in order to evaluate the position.  default: 1", 
          "long form argument": "--min-alternate-count", 
          "short form argument": "-mac"
        }, 
        {
          "data type": "flag", 
          "description": "Exclude observations which do not fully span the dynamically-determined detection window. default: use all observations, dividing partial support across matching haplotypes when generating haplotypes.", 
          "long form argument": "--no-partial-observations", 
          "short form argument": "-npo"
        }, 
        {
          "data type": "integer", 
          "description": "Require at least this coverage to process a site. default: 0", 
          "long form argument": "--min-coverage", 
          "short form argument": "-mc"
        }, 
        {
          "data type": "flag", 
          "description": "Disable use of aggregate probability of observation balance between alleles as a component of the priors.", 
          "long form argument": "--allele-balance-priors-off", 
          "short form argument": "-a"
        }, 
        {
          "data type": "string", 
          "description": "Integrate all genotype combinations in our posterior space which include no more than N samples with their Mth best.", 
          "long form argument": "--posterior-integration-limits", 
          "short form argument": "-W"
        }, 
        {
          "data type": "flag", 
          "description": "Assume that samples result from pooled sequencing. Model pooled samples using discrete genotypes across pools. When using this flag, set --ploidy to the number of alleles in each sample or use the --cnv-map to define per-sample ploidy.", 
          "long form argument": "--pooled-discrete", 
          "short form argument": "-pd"
        }, 
        {
          "data type": "string", 
          "description": "The FASTA reference index file.", 
          "long form argument": "--fasta-index", 
          "short form argument": "-fx"
        }, 
        {
          "data type": "flag", 
          "description": "Use legacy (polybayes equivalent) genotype likelihood calculations.", 
          "long form argument": "--legacy-gls", 
          "short form argument": "-lg"
        }, 
        {
          "data type": "string", 
          "description": "Limit analysis to targets listed in the BED-format FILE.", 
          "long form argument": "--targets", 
          "short form argument": "-t"
        }, 
        {
          "data type": "integer", 
          "description": "Require at least this sum of quality of observation supporting an alternate allele within a single individual in order to evaluate the position.  default: 0", 
          "long form argument": "--min-alternate-qsum", 
          "short form argument": "-maq"
        }, 
        {
          "data type": "flag", 
          "description": "Skip sample genotypings for which the sample has no supporting reads.", 
          "long form argument": "--exclude-unobserved-genotypes", 
          "short form argument": "-N"
        }, 
        {
          "data type": "flag", 
          "description": "Turn off left-alignment of indels, which is enabled by default.", 
          "long form argument": "--dont-left-align-indels", 
          "short form argument": "-dla"
        }, 
        {
          "data type": "integer", 
          "description": "Require at least this count of observations supporting an alternate allele within the total population in order to use the allele in analysis.  default: 1", 
          "long form argument": "--min-alternate-total", 
          "short form argument": "-mat"
        }, 
        {
          "data type": "integer", 
          "description": "Iterate no more than N times during genotyping step. default: 1000.", 
          "long form argument": "--genotyping-max-iterations", 
          "short form argument": "-gmi"
        }, 
        {
          "data type": "flag", 
          "description": "Ignore SNP alleles.", 
          "long form argument": "--no-snps", 
          "short form argument": "-I"
        }
      ], 
      "description": "Population call variants using Freebayes, filtering the results with standard filtering methods."
    }, 
    "gatk-genotype": {
      "arguments": [
        {
          "data type": "integer", 
          "description": "The number of threads.", 
          "long form argument": "--threads", 
          "short form argument": "-t"
        }, 
        {
          "data type": "string", 
          "description": "The reference FASTA index file.", 
          "long form argument": "--index", 
          "short form argument": "-x"
        }, 
        {
          "data type": "string", 
          "description": "The target genomic region.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "One or more specific annotations to apply to variant calls.", 
          "long form argument": "--annotation", 
          "short form argument": "-n"
        }, 
        {
          "data type": "string", 
          "description": "The input GVCF file(s).", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The reference FASTA file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The type of analysis to run.", 
          "long form argument": "--analysis-type", 
          "short form argument": "-a"
        }, 
        {
          "data type": "string", 
          "description": "The minimum level of logging.", 
          "long form argument": "--logging-level", 
          "short form argument": "-l"
        }, 
        {
          "data type": "string", 
          "description": "The reference FASTA dictionary file.", 
          "long form argument": "--fasta-dictionary", 
          "short form argument": "-d"
        }
      ], 
      "description": "Joint call genotypes from a list of GVCF files."
    }, 
    "gatk-gvcf": {
      "arguments": [
        {
          "data type": "integer", 
          "description": "The number of data threads. Each data thread uses the full amount of memory normally given to a single run. For example, if a run typically uses 2Gb, using 2 data threads will require 4Gb of memory.", 
          "long form argument": "--data-threads", 
          "short form argument": "-dt"
        }, 
        {
          "data type": "string", 
          "description": "The output GVCF file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The genomic regions to analyze.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "integer", 
          "description": "The number of CPU threads allocated to each data thread. CPU threads share the memory allocated to the data thread, so increasing this value does not effect the memory usage.", 
          "long form argument": "--cpu-threads", 
          "short form argument": "-t"
        }, 
        {
          "data type": "string", 
          "description": "A VCF file(s) containing known variants that will be supplied to the base quality recalibration step alone.", 
          "long form argument": "--known-recalibration", 
          "short form argument": "-kr"
        }, 
        {
          "data type": "string", 
          "description": "A VCF file containing known variant alleles.", 
          "long form argument": "--known-sites", 
          "short form argument": "-k"
        }, 
        {
          "data type": "string", 
          "description": "The input bam file(s).", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The FASTA reference.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }
      ], 
      "description": "Prepare the BAM file for the haplotype caller by realigning indels and recalibrating the base qualities and generate gvcf files for each sample."
    }, 
    "gatk-vqsr": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The reference FASTA file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The output tranches file used by ApplyRecalibration for SNPs.", 
          "long form argument": "--snp-tranches-file", 
          "short form argument": "-stf"
        }, 
        {
          "data type": "string", 
          "description": "The output filtered and recalibrated VCF file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The output recal file used by ApplyRecalibration for INDELs.", 
          "long form argument": "--out-indel-recal", 
          "short form argument": "-oi"
        }, 
        {
          "data type": "string", 
          "description": "A list of dbsnp sites for which to apply a prior probability of being correct but which aren't used by the algorithm (training and truth sets are required to run).", 
          "long form argument": "--resource-dbsnp", 
          "short form argument": "-rd"
        }, 
        {
          "data type": "string", 
          "description": "A list of omni sites for which to apply a prior probability of being correct but which aren't used by the algorithm (training and truth sets are required to run).", 
          "long form argument": "--resource-omni", 
          "short form argument": "-ro"
        }, 
        {
          "data type": "string", 
          "description": "A list of indel sites for which to apply a prior probability of being correct but which aren't used by the algorithm (training and truth sets are required to run).", 
          "long form argument": "--resource-indel", 
          "short form argument": "-ri"
        }, 
        {
          "data type": "string", 
          "description": "A list of 1000G SNP sites for which to apply a prior probability of being correct but which aren't used by the algorithm (training and truth sets are required to run).", 
          "long form argument": "--resource-1000g", 
          "short form argument": "-rs"
        }, 
        {
          "data type": "integer", 
          "description": "Maximum number of Gaussians for the positive model.", 
          "long form argument": "--max-gaussians", 
          "short form argument": "-mg"
        }, 
        {
          "data type": "string", 
          "description": "The output recal file used by ApplyRecalibration for SNPs.", 
          "long form argument": "--out-snp-recal", 
          "short form argument": "-os"
        }, 
        {
          "data type": "string", 
          "description": "The joint called VCF file to be recalibrated.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The output filtered and recalibrated VCF file in which each variant is annotated with its VQSLOD value for SNPs.", 
          "long form argument": "--snp-vcf", 
          "short form argument": "-sv"
        }, 
        {
          "data type": "float", 
          "description": "The levels of novel false discovery rate (FDR, implied by ti/tv) at which to slice the data. (in percent, that is 1.0 for 1 percent).", 
          "long form argument": "--tranche", 
          "short form argument": "-c"
        }, 
        {
          "data type": "string", 
          "description": "The output tranches file used by ApplyRecalibration for INDELs.", 
          "long form argument": "--indel-tranches-file", 
          "short form argument": "-itf"
        }, 
        {
          "data type": "string", 
          "description": "One or more specific annotations to apply to variant calls.", 
          "long form argument": "--annotation", 
          "short form argument": "-n"
        }, 
        {
          "data type": "integer", 
          "description": "The truth sensitivity level at which to start filtering.", 
          "long form argument": "--truth-sensitivity", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "A list of hapmap sites for which to apply a prior probability of being correct but which aren't used by the algorithm (training and truth sets are required to run).", 
          "long form argument": "--resource-hapmap", 
          "short form argument": "-rh"
        }
      ], 
      "description": "Recalibrate the variant scores. It is recommended that this is performed if there are sufficient variants (one whole exome or at least 30 exomes)."
    }, 
    "get-indels": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output standardized VCF file including indels only.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The genomic region to analyse.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "The filter expression (enclose in quotes on the command line).", 
          "long form argument": "--filter-expression", 
          "short form argument": "-f"
        }, 
        {
          "data type": "string", 
          "description": "The input sorted VCF file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The reference FASTA file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "A text file containing a list of samples on which to subset.", 
          "long form argument": "--samples-files", 
          "short form argument": "-s"
        }
      ], 
      "description": "Get all indels from a VCF files and standardize the resulting VCF file."
    }, 
    "get-region-coverage": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output pileup data.", 
          "long form argument": "--pileup", 
          "short form argument": "-p"
        }, 
        {
          "data type": "string", 
          "description": "An input file list of all transcripts.", 
          "long form argument": "--transcripts", 
          "short form argument": "-t"
        }, 
        {
          "data type": "string", 
          "description": "The genomic region to consider.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "The input BAM file whose coverage will be calculated.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }
      ], 
      "description": "Population call variants using Freebayes, filtering the results with standard filtering methods."
    }, 
    "index-bam": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The input BAM file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The index file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "flag", 
          "description": "create non-standard (depth based) index file (*.bti). Default behaviour is to create standard BAM index (*.bai)", 
          "long form argument": "--depth-based-index", 
          "short form argument": "-b"
        }
      ], 
      "description": "Index BAM files."
    }, 
    "index-fasta": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The input FASTA file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The output FASTA index file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }
      ], 
      "description": "Index a FASTA file."
    }, 
    "index-vcf": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output index file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "flag", 
          "description": "Overwrite existing index.", 
          "long form argument": "--force-overwrite", 
          "short form argument": "-f"
        }, 
        {
          "data type": "string", 
          "description": "The file to be indexed.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }
      ], 
      "description": "Index VCF files."
    }, 
    "kmer-histogram": {
      "arguments": [
        {
          "data type": "integer", 
          "description": "The number of threads to use for counting kmers.", 
          "long form argument": "--threads", 
          "short form argument": "-t"
        }, 
        {
          "data type": "flag", 
          "description": "Generate a full histogram. Don't skip count 0. (default: true).", 
          "long form argument": "--full", 
          "short form argument": "-f"
        }, 
        {
          "data type": "flag", 
          "description": "Count both strand, canonical representation (default: true).", 
          "long form argument": "--canonical", 
          "short form argument": "-c"
        }, 
        {
          "data type": "float", 
          "description": "Only include bars in histogram if their counts are greated than this percentage of the maximum observed count.", 
          "long form argument": "--percent", 
          "short form argument": "-p"
        }, 
        {
          "data type": "string", 
          "description": "The second mate FASTQ file.", 
          "long form argument": "--fastq2", 
          "short form argument": "-q2"
        }, 
        {
          "data type": "integer", 
          "description": "The kmer length.", 
          "long form argument": "--kmer", 
          "short form argument": "-k"
        }, 
        {
          "data type": "string", 
          "description": "The x axis label [bin].", 
          "long form argument": "--x-label", 
          "short form argument": "-x"
        }, 
        {
          "data type": "string", 
          "description": "The plot title.", 
          "long form argument": "--title", 
          "short form argument": "-l"
        }, 
        {
          "data type": "string", 
          "description": "The first mate FASTQ file.", 
          "long form argument": "--fastq", 
          "short form argument": "-q"
        }, 
        {
          "data type": "integer", 
          "description": "The initial hash size.", 
          "long form argument": "--size", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "The output file containing the kmer counts (extension: .jf).", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The y axis label [value].", 
          "long form argument": "--y-label", 
          "short form argument": "-y"
        }, 
        {
          "data type": "string", 
          "description": "The output histogram plot.", 
          "long form argument": "--histogram", 
          "short form argument": "-hs"
        }
      ], 
      "description": "Count the number of occurences of kmers of a specified length and then construct a histogram of the counts."
    }, 
    "merge-bam": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The BAM index file(s).", 
          "long form argument": "--index", 
          "short form argument": "-x"
        }, 
        {
          "data type": "string", 
          "description": "The output merged BAM file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "only read data from this genomic region.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "The input BAM file(s).", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }
      ], 
      "description": "Merge a set of BAM files."
    }, 
    "merge-vcf": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output merged, compressed VCF file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The input VCF files to merge.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }
      ], 
      "description": "Merge a set of VCF files."
    }, 
    "mosaik": {
      "arguments": [
        {
          "data type": "integer", 
          "description": "Specifies the number of threads to use for the aligner.", 
          "long form argument": "--threads", 
          "short form argument": "-t"
        }, 
        {
          "data type": "string", 
          "description": "The library name. e.g. g1k-sc-NA18944-JPT-1.", 
          "long form argument": "--lane", 
          "short form argument": "-l"
        }, 
        {
          "data type": "string", 
          "description": "The Mosaik format reference genome (.dat).", 
          "long form argument": "--mosaik-reference", 
          "short form argument": "-m"
        }, 
        {
          "data type": "string", 
          "description": "The input fastq file (second mate).", 
          "long form argument": "--fastq2", 
          "short form argument": "-q2"
        }, 
        {
          "data type": "integer", 
          "description": "Specifies the maximum number of hashes for the special reference sequences.", 
          "long form argument": "--special-reference-hashes", 
          "short form argument": "-sh"
        }, 
        {
          "data type": "string", 
          "description": "The sample name. e.g. NA12878.", 
          "long form argument": "--sample-name", 
          "short form argument": "-sam"
        }, 
        {
          "data type": "string", 
          "description": "Sequencing technology: '454', 'helicos', 'illumina', 'illumina_long', 'sanger' or 'solid'.", 
          "long form argument": "--sequencing-technology", 
          "short form argument": "-st"
        }, 
        {
          "data type": "string", 
          "description": "The input Mosaik jump database stub.", 
          "long form argument": "--jump-database", 
          "short form argument": "-j"
        }, 
        {
          "data type": "string", 
          "description": "Neural network file for Mosaik mapping quality scores (single end).", 
          "long form argument": "--ann-se", 
          "short form argument": "-as"
        }, 
        {
          "data type": "string", 
          "description": "The prefix attached to 'special' reference sequences.", 
          "long form argument": "--special-reference-prefix", 
          "short form argument": "-s"
        }, 
        {
          "data type": "integer", 
          "description": "Specifies the minimum length of an alignment candidate.", 
          "long form argument": "--alignment-candidate-threshold", 
          "short form argument": "-act"
        }, 
        {
          "data type": "string", 
          "description": "The input fastq file (first mate).", 
          "long form argument": "--fastq", 
          "short form argument": "-q"
        }, 
        {
          "data type": "string", 
          "description": "Neural network file for Mosaik mapping quality scores (paired end).", 
          "long form argument": "--ann-pe", 
          "short form argument": "-ap"
        }, 
        {
          "data type": "string", 
          "description": "The sequencing center name.", 
          "long form argument": "--center-name", 
          "short form argument": "-c"
        }, 
        {
          "data type": "integer", 
          "description": "The hash-size used in Mosaik [4 - 32].", 
          "long form argument": "--hash-size", 
          "short form argument": "-hs"
        }, 
        {
          "data type": "string", 
          "description": "The read group id. e.g. SRR009060.", 
          "long form argument": "--read-group-id", 
          "short form argument": "-id"
        }, 
        {
          "data type": "integer", 
          "description": "The median fragment length.", 
          "long form argument": "--median-fragment-length", 
          "short form argument": "-mfl"
        }, 
        {
          "data type": "string", 
          "description": "The output read archive.", 
          "long form argument": "--read-archive", 
          "short form argument": "-a"
        }, 
        {
          "data type": "integer", 
          "description": "Specifies the maximum number of positions stored for each hash.", 
          "long form argument": "--maximum-hashes-per-seed", 
          "short form argument": "-mhp"
        }, 
        {
          "data type": "string", 
          "description": "The platform unit. e.g. IL12_490_5.", 
          "long form argument": "--platform", 
          "short form argument": "-pu"
        }
      ], 
      "description": "Align fastq files using Mosaik. In this version additional 'special' reference sequences are included (usually mobile element insertions) in the reference."
    }, 
    "normalize-vcf": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The genomic region in which to perform the analysis.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "The input VCF file to be normalized.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The FASTA reference sequence file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "A file containing list of genomic regions to analyse.", 
          "long form argument": "--regions-file", 
          "short form argument": "-rgf"
        }, 
        {
          "data type": "string", 
          "description": "The FASTA reference index file.", 
          "long form argument": "--fasta-index", 
          "short form argument": "-fx"
        }, 
        {
          "data type": "integer", 
          "description": "Window size for local sorting of variants [10000].", 
          "long form argument": "--window", 
          "short form argument": "-w"
        }
      ], 
      "description": "Normalize a VCF file using vt and index with tabix."
    }, 
    "regions-coord": {
      "arguments": [
        {
          "data type": "integer", 
          "description": "The value to add to each given coordinate to define the upper value of the window.", 
          "long form argument": "--maximum", 
          "short form argument": "-x"
        }, 
        {
          "data type": "integer", 
          "description": "The chromosome on which the windows are to be applied.", 
          "long form argument": "--chromosome", 
          "short form argument": "-c"
        }, 
        {
          "data type": "string", 
          "description": "A list of region windows.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "A file containing a list of genomic positions around which to generate windows (chromosome entered with --chromosome).", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "integer", 
          "description": "The value to subtract from each given coordinate to define the lower value of the window.", 
          "long form argument": "--minimum", 
          "short form argument": "-m"
        }
      ], 
      "description": "Generate a list of regions based on a list of chromosome coordinates."
    }, 
    "regions-dict": {
      "arguments": [
        {
          "data type": "integer", 
          "description": "The size of the genomic regions.", 
          "long form argument": "--window-size", 
          "short form argument": "-w"
        }, 
        {
          "data type": "string", 
          "description": "A list of genomic regions.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "bool", 
          "description": "Generate regions only for the reference sequences contained in the file specified with --reference-sequences.", 
          "long form argument": "--invert-sequences", 
          "short form argument": "-v"
        }, 
        {
          "data type": "string", 
          "description": "A reference fasta dictionary.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "Only regions from the reference sequences in this file will be output. If --invert-sequences is also set, the sequences not contained in the file will be output.", 
          "long form argument": "--reference-sequences", 
          "short form argument": "-s"
        }
      ], 
      "description": "Generate a list of genomic regions based on a FASTA dictionary file."
    }, 
    "standardize-vcf": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The reference FASTA file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "A text file containing a list of samples on which to subset.", 
          "long form argument": "--samples-files", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "The output standardized VCF file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The genomic region to analyse.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "The input sorted VCF file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }
      ], 
      "description": "Standardize a VCF file. This involves steps including normalization of variants, removing duplicates etc."
    }, 
    "subset-vcf": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output subsetted compressed VCF file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The genomic region in which to perform the analysis.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "The filter expression (enclose in quotes on the command line).", 
          "long form argument": "--filter-expression", 
          "short form argument": "-f"
        }, 
        {
          "data type": "string", 
          "description": "A file containing list of samples on which to subset.", 
          "long form argument": "--samples-file", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "The input compressed VCF file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The FASTA reference.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "A file containing a list of genomic regions to analyse.", 
          "long form argument": "--regions-file", 
          "short form argument": "-rgf"
        }
      ], 
      "description": "Subset a compressed VCF file on a list of samples and normalize the records."
    }, 
    "tangram": {
      "arguments": [
        {
          "data type": "integer", 
          "description": "The number of threads to use.", 
          "long form argument": "--threads", 
          "short form argument": "-t"
        }, 
        {
          "data type": "string", 
          "description": "The output VCF file containing the MEI calls.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "integer", 
          "description": "The minimum number of normal fragments in a library.", 
          "long form argument": "--minimum-fragments", 
          "short form argument": "-mf"
        }, 
        {
          "data type": "string", 
          "description": "The region of interest in the genome.", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "An input file containing a list of BAM files.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }, 
        {
          "data type": "string", 
          "description": "The output path for Tangram files.", 
          "long form argument": "--path", 
          "short form argument": "-p"
        }, 
        {
          "data type": "string", 
          "description": "The reference file created by Tangram index.", 
          "long form argument": "--tangram-reference", 
          "short form argument": "-a"
        }, 
        {
          "data type": "string", 
          "description": "Library information file (generated by tangram-scan).", 
          "long form argument": "--library-file", 
          "short form argument": "-l"
        }, 
        {
          "data type": "string", 
          "description": "Fragment length distribution information file (generated by tangram-scan).", 
          "long form argument": "--histogram-file", 
          "short form argument": "-ht"
        }
      ], 
      "description": "INCLUDE DESCRIPTION"
    }, 
    "tangram-bam": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The output BAM file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The mobile element fasta file.", 
          "long form argument": "--mobile-element-fasta", 
          "short form argument": "-m"
        }, 
        {
          "data type": "string", 
          "description": "The genomic region to consider (whole genome or chromosome recommended).", 
          "long form argument": "--region", 
          "short form argument": "-rg"
        }, 
        {
          "data type": "string", 
          "description": "The input BAM file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }
      ], 
      "description": "Add tags expected by Tangram to BAM files generated by aligners other than Mosaik."
    }, 
    "tangram-index": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The input reference FASTA file.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The input reference file containing the insertion sequences.", 
          "long form argument": "--special-reference", 
          "short form argument": "-s"
        }, 
        {
          "data type": "string", 
          "description": "The output reference file.", 
          "long form argument": "--tangram-reference", 
          "short form argument": "-a"
        }
      ], 
      "description": "Population call variants using Freebayes, filtering the results with standard filtering methods."
    }, 
    "vcf-primitives": {
      "arguments": [
        {
          "data type": "string", 
          "description": "The FASTA reference.", 
          "long form argument": "--fasta-reference", 
          "short form argument": "-r"
        }, 
        {
          "data type": "string", 
          "description": "The output compressed VCF file.", 
          "long form argument": "--out", 
          "short form argument": "-o"
        }, 
        {
          "data type": "string", 
          "description": "The input compressed VCF file.", 
          "long form argument": "--in", 
          "short form argument": "-i"
        }
      ], 
      "description": "Break complex variants into their constituent primitive units and normalize."
    }
  }, 
  "resources": {
    "homo_sapiens": {
      "commit": "ec95090fc35b616ec3aae8fa4fb18336b56d2411"
    }, 
    "tutorial": {
      "commit": "e91fff213ebda541c537526c67fbd28fe1cdbd26"
    }
  }, 
  "tools": {
    "bamtools": {
      "authors": [
        "Derek Barnett"
      ], 
      "commit": "7f8b301e2f43d4d50a79f6184f1c132c9e33d324", 
      "emails": [
        "derekwbarnett@gmail.com"
      ], 
      "papers": [
        "Barnett D. W., et al. BamTools: a C++ API and toolkit for analyzing and managing BAM files. Bioinformatics 2011;27:1691-1692."
      ], 
      "web_pages": [
        "https://github.com/pezmaster31/bamtools"
      ]
    }, 
    "bamutil": {
      "authors": [
        "Mary Kate Wing"
      ], 
      "commit": "9b9097ea7dd9bb6efa6fde99d495338e9c189813", 
      "emails": [
        "mktrost@umich.edu"
      ], 
      "web_pages": [
        "git clone https://github.com/statgen/bamUtil.git"
      ]
    }, 
    "freebayes": {
      "authors": [
        "Erik Garrison"
      ], 
      "citations": [
        "Garrison E, Marth G. Haplotype-based variant detection from short-read sequencing. arXiv preprint arXiv:1207.3907 [q-bio.GN] 2012"
      ], 
      "commit": "b8b8a84e6da015ce8358502848eedf66e70a2ead", 
      "emails": [
        "erik.garrison@gmail.com"
      ], 
      "papers": [
        "http://arxiv.org/abs/1207.3907"
      ], 
      "web_pages": [
        "https://github.com/ekg/freebayes"
      ]
    }, 
    "laser": {
      "authors": [
        "Chaolong Wang", 
        "Xiaowei Zhan"
      ], 
      "emails": [
        "chaolong@umich.edu"
      ], 
      "papers": [
        "C Wang, X Zhan, J Bragg-Gresham, HM Kang, D Stambolian, E Chew, K Branham, J Heckenlively, The FUSION Study, RS Fulton, RK Wilson, ER Mardis, X Lin, A Swaroop, S Z\u00f6llner, GR Abecasis (2014) Ancestry estimation and control of population stratification for sequence-based association studies. Nature Genetics, 46: 409-415", 
        "C Wang, X Zhan, L Liang, GR Abecasis, X Lin (2015) Improved Ancestry Estimation for both Genotyping and Sequencing Data using Projection Procrustes Analysis and Genotype Imputation. The American Journal of Human Genetics, Volume 96, Issue 6, 926-937"
      ], 
      "web_pages": [
        "http://csg.sph.umich.edu/chaolong/LASER/"
      ]
    }, 
    "vt": {
      "authors": [
        "Adrian Tan"
      ], 
      "commit": "50e157b3a9ba281b66c284f78fa8835f138dfefa", 
      "papers": [
        "Unified representation of genetic variants, Adrian Tan, Goncalo R. Abecasis and Hyun Min Kang, Bioinformatics, 2015, 1-3, doi: 10.1093/bioinformatics/btv112"
      ], 
      "web_pages": [
        "http://genome.sph.umich.edu/wiki/Vt"
      ]
    }
  }
}